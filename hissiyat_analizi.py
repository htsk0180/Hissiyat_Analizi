# -*- coding: utf-8 -*-
"""Hissiyat_Analizi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dTMY737aJ-eRU2glOcX5JWlrpofuLRI7
"""

# Commented out IPython magic to ensure Python compatibility.
# Kimlik Doğrulama.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

"""`Hissiyat analizi` metinlerdeki öznel bilgiyi bulmak için bağlamsal bir data mining yöntemidir. Hissiyat analizi üretilen ürünlerin ya da sunulan hizmetin kişiler tarafından beğenilip beğenilmediği ya da bir görüş belirtmek istemediği durumları anlamamıza yardımcı olur."""

# ilgili kütüphane ve veri setinin yüklenmesi.
import pandas as pd
data = pd.read_excel("/gdrive/My Drive/Calisma_ortami/Uygulamalar/reviews.xlsx")
data = data.sample(frac=1).reset_index(drop=True)

data.head()

data['label'].value_counts()

# veri ön işleme
import string
import re
import nltk
nltk.download("stopwords")
from nltk.corpus import stopwords

noktalama = string.punctuation
etkisiz = stopwords.words('turkish')
print(noktalama)
print(etkisiz)

for d in data['review'].head():
  print(d+ '\n----------------------')
  # etkisiz kelimelerin atılması
  temp = ''
  for word in d.split():
    if word not in etkisiz and not word.isnumeric():
      temp += word + ' '
  print(temp + '\n********************')

for d in data['review'].head():
  print(d+ '\n------------------')
  temp = ''
  for word in d:
    if word not in noktalama:
      temp += word
  print(temp + '\n*********************')
  d = temp

data.to_csv(r'/gdrive/My Drive/Calisma_ortami/Uygulamalar/cleaned.csv', index = False)

# temizlenmiş veriyi yüklüyoruz.
import pandas as pd
data = pd.read_csv('/gdrive/My Drive/Calisma_ortami/Uygulamalar/cleaned.csv', sep=",")
print(data.head())

# temizlenmiş veri setini train ve test olarak ayırıyoruz.
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(data['review'].head(30000).values.astype('U'),
                                                 data['label'].head(30000).values.astype('U'), test_size=0.33,random_state=42)
print(X_train.shape)
print(X_test.shape)

# train kümesindeki cümlelerin sayma vektörlerini çıkarıyoruz.
from sklearn.feature_extraction.text import CountVectorizer
count_vect = CountVectorizer()
X_train_counts = count_vect.fit_transform(X_train)
print(X_train_counts.shape)

# train kümesindeki cümlelerin TF*IDF vektörlerini sayma vektörlerinden oluşturuyoruz.
from sklearn.feature_extraction.text import TfidfTransformer
tfidf_transformer = TfidfTransformer()
X_train_tdidf = tfidf_transformer.fit_transform(X_train_counts)
print(X_train_tdidf.shape)

# çok modlu naive bayes sınıflandırıcı eğitiyoruz.
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB().fit(X_train_tdidf,y_train)
X_test_counts = count_vect.transform(X_test)
X_test_tfidf = tfidf_transformer.transform(X_test_counts)

# sınıflandırıcı ile test seti üzerinden tahminleme yapıyoruz.
y_pred = clf.predict(X_test_tfidf)
for review, sentiment in zip(X_test[:-5],y_pred[:]):
  print('%r => %s' % (review,sentiment))

# performans sonuçları
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_pred))

